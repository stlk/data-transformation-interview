{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be ingesting, transforming, storing, transforming, and displaying some data.\n",
    "\n",
    "### 1. First, we'll need data\n",
    "\n",
    "ImageNet (http://imagenet.stanford.edu/) is a commonly used dataset in machine learning research. We'll be using its taxonomy system.\n",
    "\n",
    "When you go to http://imagenet.stanford.edu/synset?wnid=n02486410, you'll see a tree on the left. Your job is to get this tree and transform it into a linear form, like this:\n",
    "\n",
    "```\n",
    "[\n",
    "    {name: 'ImageNet 2011 Fall Release', size: 32326},\n",
    "    {name: 'ImageNet 2011 Fall Release > plant, flora, plant life', size: 4486},\n",
    "    {name: 'ImageNet 2011 Fall Release > plant, flora, plant life > phytoplankton', size: 2},\n",
    "    {name: 'ImageNet 2011 Fall Release > plant, flora, plant life > phytoplankton > planktonic algae', size: 0},\n",
    "    {name: 'ImageNet 2011 Fall Release > plant, flora, plant life > phytoplankton > diatom', size: 0},\n",
    "    {name: 'ImageNet 2011 Fall Release > plant, flora, plant life > microflora', size: 0},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "We'll use `>` as a separator of categories/subcategories.\n",
    "\n",
    "You can get all the data you need here https://s3.amazonaws.com/static.operam.com/assignment/structure_released.xml\n",
    "\n",
    "### 2. Second, we'll need to store it somewhere\n",
    "\n",
    "Create a database (use any database system you like or want to try) to store these tuples `(string, number)` and fill it with the data you obtained in the first step.\n",
    "\n",
    "### 3. Making sense of it\n",
    "\n",
    "Next, we'll convert it back to a tree. Like this:\n",
    "\n",
    "```\n",
    "{\n",
    "    name: 'ImageNet 2011 Fall Release',\n",
    "    size: 32326,\n",
    "    children: [\n",
    "        {\n",
    "            name: 'plant, flora, plant life',\n",
    "            size: 4486,\n",
    "            children: [\n",
    "                {\n",
    "                    name: 'phytoplankton',\n",
    "                    size: 2,\n",
    "                    children: [\n",
    "                        ...\n",
    "                    ]\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "* Can you write an algorithm that will output such a tree? No cheating here, you have to read this data in a linear form from the database.\n",
    "* What is the complexity of your algorithm (in big O notation)?\n",
    "\n",
    "### 3. Now it's time to show the data again\n",
    "\n",
    "* Can you design and build an interface to show this data?\n",
    "* Can you implement search in this UI?\n",
    "\n",
    "<hr>\n",
    "\n",
    "Use React for frontend, JS/Python for backend and any other frameworks or libraries. If you prefer to use something else, please let me know.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "file_path = \"structure_released.xml\"\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Not sure why the number differ, but there are 60942 synsets in the document.\n",
    "# base = root.findall(\".//synset\")\n",
    "# len(base)\n",
    "\n",
    "base = root.find(\".synset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crawl(synset):\n",
    "    children = [crawl(child) for child in synset.getchildren()]\n",
    "    if children:\n",
    "        return ((synset.attrib['words'], sum([count for _, count, _ in children]) + len(children), children))\n",
    "    else:\n",
    "        return (synset.attrib['words'], 0, children)\n",
    "\n",
    "structure_with_counts = crawl(base)\n",
    "structure_with_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(items, prefix = ''):\n",
    "    for name, count, children in items:\n",
    "        prefixed_name = f'{prefix} > {name}' if prefix else name\n",
    "        yield {'name': prefixed_name, 'size': count}\n",
    "        if children:\n",
    "            yield from flatten(children, prefix = prefixed_name)\n",
    "\n",
    "flattened_structure = list(flatten([structure_with_counts]))\n",
    "flattened_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('synsets.pickle', 'wb') as f:\n",
    "    pickle.dump(flattened_structure, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('synsets.pickle', 'rb') as f:\n",
    "    flattened_structure = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         35738965 function calls in 18.896 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    60941    0.448    0.000   18.466    0.000 <ipython-input-15-d9b28130d567>:17(update_nested_dict)\n",
      " 34711270    8.047    0.000    8.047    0.000 <ipython-input-15-d9b28130d567>:20(<lambda>)\n",
      "    60942    0.240    0.000   18.825    0.000 <ipython-input-15-d9b28130d567>:27(reducer)\n",
      "   361604    0.487    0.000   17.998    0.000 <ipython-input-15-d9b28130d567>:4(first_true)\n",
      "        1    0.000    0.000   18.896   18.896 <ipython-input-15-d9b28130d567>:57(generate_tree)\n",
      "        1    0.071    0.071   18.896   18.896 {built-in method _functools.reduce}\n",
      "    60942    0.014    0.000    0.014    0.000 {built-in method builtins.len}\n",
      "   361604    9.463    0.000   17.510    0.000 {built-in method builtins.next}\n",
      "    60717    0.020    0.000    0.020    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    60942    0.105    0.000    0.105    0.000 {method 'split' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def first_true(iterable, default=False, pred=None):\n",
    "    \"\"\"Returns the first true value in the iterable.\n",
    "\n",
    "    If no true value is found, returns *default*\n",
    "\n",
    "    If *pred* is not None, returns the first item\n",
    "    for which pred(item) is true.\n",
    "\n",
    "    \"\"\"\n",
    "    # first_true([a,b,c], x) --> a or b or c or x\n",
    "    # first_true([a,b], x, f) --> a if f(a) else b if f(b) else x\n",
    "    return next(filter(pred, iterable), default)\n",
    "\n",
    "def update_nested_dict(nested_dict, keys, size):\n",
    "    cur = nested_dict\n",
    "    for path_item in keys[1:]:\n",
    "        find_result = first_true(cur['children'], pred = lambda child: child['name'] == path_item)\n",
    "        if find_result:\n",
    "            cur = find_result\n",
    "        else:\n",
    "            cur['children'].append({'name': path_item, 'size': size,'collapsed': True, 'children': []})\n",
    "            \n",
    "\n",
    "def reducer(value, element):\n",
    "    keys = element['name'].split(' > ')\n",
    "\n",
    "    if len(keys) == 1:\n",
    "        return {\n",
    "            'name': element['name'],\n",
    "            'size': element['size'],\n",
    "            'collapsed': True,\n",
    "            'children': []\n",
    "        }\n",
    "    \n",
    "    update_nested_dict(value, keys, element['size'])\n",
    "    return value\n",
    "\n",
    "import cProfile\n",
    "\n",
    "def do_cprofile(func):\n",
    "    def profiled_func(*args, **kwargs):\n",
    "        profile = cProfile.Profile()\n",
    "        try:\n",
    "            profile.enable()\n",
    "            result = func(*args, **kwargs)\n",
    "            profile.disable()\n",
    "            return result\n",
    "        finally:\n",
    "            profile.print_stats()\n",
    "    return profiled_func\n",
    "    \n",
    "from functools import reduce\n",
    "\n",
    "@do_cprofile\n",
    "def generate_tree():\n",
    "    return reduce(reducer, flattened_structure, {})\n",
    "\n",
    "tree = generate_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performace\n",
    "\n",
    "I think that complexity of this algorhytm is n^3. Not really sure about it. However after looking into profiling results I think that best way to improve performance would be to use lookup table to avoid scanning entire tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('synsets.json', 'w') as f:\n",
    "    json.dump(tree, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
